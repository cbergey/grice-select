---
title: "Listeners use descriptive contrast to disambiguate novel referents"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

 

abstract: 

  "Human listeners are often faced with referential ambiguity. Description is one cue listeners can use to narrow down referents. Beyond narrowing potential referents to those that match a descriptor, listeners may further infer that a described object is one that contrasts with other relevant objects of the same type (e.g., ``The tall cup'' contrasts with another, shorter cup). This kind of contrastive inference is known to operate in online processing as listeners try to visually identify a referent as an utterance progresses (Sedivy et al., 1999). However, it is not known whether listeners use this type of inference to explicitly guide their choice of a referent. In three experiments, we test whether adult listeners use color and size adjectives contrastively to guide their mapping of a novel word onto a novel referent. We find that while participants use size adjectives contrastively to guide referent choice, they do not do so using color adjectives (Experiment 1). Further, even when color is described with more relative language (Experiment 2) or emphasized with prosodic contrastive stress (Experiment 3), participants do not consistently interpret color contrastively to guide referent choice. These results demonstrate that listeners are able to use adjective contrast to disambiguate a novel word's referent, but do not treat all adjective types as equally contrastive."

#     "The abstract should be one paragraph, indented 1/8 inch on both sides,
# in 9 point font with single spacing. The heading Abstract should
# be 10 point, bold, centered, with one line space below it. This
# one-paragraph abstract section is required only for standard spoken
# papers and standard posters (i.e., those presentations that will be
# represented by six page papers in the Proceedings)."
    
keywords:
    "reference resolution; pragmatics; prenominal adjectives"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb",
                      fig.path='figs/', echo=F, warning=F, cache=F, message=F,
                      sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(tidyverse)
library(lme4)
library(broom)
library(broom.mixed)
library(here)
library(english)
library(ggthemes)
library(gridExtra)
library(directlabels)
library(tidyboot)
library(papaja)

theme_set(theme_classic(base_size = 10))
logit <- function(x) {log(x/(1-x))}

options(digits=2)
```

# Introduction

When trying to communicate, human listeners are faced with uncertainty. Novice listeners---children---face a continuous speech stream filled with unknown words referring to unformed concepts. Even seasoned listeners---adults---contend with noise, variable pronunciation, ambiguous meanings, and the occasional unknown word, too. Fortunately, listeners bring sensitive phonetic, syntactic, and semantic skills to the task, allowing them to reduce ambiguity during conversations and over developmental time. Most of these well-documented skills are concerned with the listener’s understanding of the speaker’s utterance alone. But communication occurs in context: in a rich world to which language refers. Listeners’ ability to combine utterance information with context---their pragmatic ability---may be a powerful tool in resolving referential ambiguity.

One potential pragmatic tool for reducing referential uncertainty is contrastive inference. Contrastive inferences are those inferences that derive from the principle that description should discriminate. This principle falls out of the more general Gricean maxim that speakers should say as much as they need to say and no more [@grice1975logic]. To the extent that communicators strive to be minimal and informative, description should discriminate between the referent and some relevant contrasting set. This contrastive inference is fairly obvious from some types of description, such as some postnominal modifiers: "The door with the lock" clearly implies a contrasting door without one [@sedivy_invoking_2002; @sedivy_pragmatic_2003-2; @nietal]. The degree of contrast implied by more common descriptive forms, such as prenominal adjectives in English, is less clear. Speakers do not always use prenominal adjectives contrastively, often describing more than is needed to establish reference [@pechmann_incremental_1989; @mangold_informativeness_1988; @engelhardt_speakers_2006]. How, then, do listeners interpret these descriptions? 

Sedivy and colleagues carried out a visual world task demonstrating that adults interpret at least some prenominal adjective use as contrastive [@sedivy_achieving_1999]. In their task, four objects appeared on a screen: a target (e.g., a tall cup), a contrastive pair (e.g., a short cup), a competitor that shares the target’s feature but not category (e.g., a tall pitcher), and an irrelevant distractor. Participants then heard a referential expression: “Pick up the tall cup.” Adults looked more quickly to the correct object when the utterance referred to an object with a same-category contrastive pair (tall cup vs. short cup) than when it referred to an object without a contrastive pair (e.g., the tall pitcher). Their results suggest that listeners expect speakers to use prenominal description when they are distinguishing between potential referents of the same type, and listeners use this inference to rapidly allocate their attention to the target as an utterance progresses. This effect was demonstrated for size and material adjectives; the results for color adjectives were mixed [@sedivy_achieving_1999; @sedivy_pragmatic_2003-2]. More recently, this contrastive processing effect was replicated with 5-year-old participants using size adjectives [@huangsnedeker2008]. These experiments demonstrate that listeners interpret at least some prenominal adjectives contrastively, and use this contrastive inference to guide their attention allocation. These results leave open, however, whether listeners use prenominal adjective contrast to resolve referential ambiguity and explicitly guide their referent choice.

In order to determine whether adults can use prenominal adjective contrast to disambiguate referents, and how those inferences are affected by adjective type, we use a reference game with novel objects. Novel objects provide both a useful experimental tool and an especially interesting testing ground for contrastive inferences. These objects avoid effects of typicality and familiarity that relate to level of description in production [@pechmann_incremental_1989; @rubio-fernandez_how_2016] on particular features [@mangold_informativeness_1988]. They have unknown names and feature distributions, creating the ambiguity necessary for our test of referential disambiguation. But the ability to disambiguate novel referents, or to establish reference with incomplete information, is also the broader problem of learning about the world. This skill would aid not only adult speakers dealing with ambiguous or degraded communicative signal, but also children who need to establish new word--referent mappings. Across the developmental span, contrastive inference could help listeners exploit regularities in language and their environment to learn about both.

# Experiment 1   

In Experiment 1, we test whether adult participants use prenominal adjective contrast to choose a novel referent. To examine whether contrast occurs across adjective types, we test participants in two conditions: color contrast and size contrast. In a task similar to that of Sedivy and colleagues (1999), we present participants with arrays of novel fruit objects. On critical trials, participants see a target object, a lure object that shares the target’s contrast feature but not its shape, and a contrastive pair that shares the target’s shape but not its contrast feature. Participants hear an utterance denoting the feature: "Find the [blue/big] dax." For the target object, use of the adjective is necessary to disambiguate from the same-shape distractor; for the lure, the adjective would be superfluous description. If participants use contrastive inference to choose novel referents, they should choose the target object. However, we do not expect listeners to treat color and size equally. Because color is often used redundantly in English while size is not [@pechmann_incremental_1989; @nadig_evidence_2002], we expect size to hold more contrastive weight, encouraging a more consistent contrastive inference.

```{r colortrial, fig.env = "figure", fig.pos = "H", fig.align='center', set.cap.width=T, num.cols.cap=1, fig.cap = "On the left: an example of a contrastive trial in which the critical feature is size. Here, the participant would hear the instruction ``Find the small dax.'' On the right: an example of a contrastive trial in which the critical feature is color. Here, the participant would hear the instruction ``Find the red dax.'' In both cases, the target is the top object."}
img <- png::readPNG("figs/sizecolorcontrast.png")
grid::grid.raster(img)
```


## Method

```{r load_data}
data <- read_csv(here("data/turk_data.csv")) %>%
  gather(item, chose, chosetarget, choselure, choseunique) %>%
  mutate(item = gsub("chose", "", item))

e1_data <- data %>% filter(type %in% c("scalar", "color"))

pilot_data <- data %>% filter(type %in% c("scalar-pilot"))

e1_color_subjs <- e1_data %>%
  filter(type == "color") %>%
  distinct(subid) %>%
  nrow()

e1_scalar_subjs <- e1_data %>%
  filter(type == "scalar") %>%
  distinct(subid) %>%
  nrow()

pilot_subjs <- pilot_data %>%
  filter(type == "scalar-pilot") %>%
  distinct(subid) %>%
  nrow()

e1_mean_data <- e1_data %>%
  filter(item != "unique") %>%
  group_by(type, searchtype, adjective_used, item, subid) %>%
  summarise(chose = mean(chose), n = n()) %>%
  tidyboot_mean(chose) %>%
  ungroup() %>%
  mutate(adjective_used = factor(adjective_used, labels = c("noun", "adjective noun"))) 

pilot_mean_data <- pilot_data %>%
  filter(item != "unique") %>%
  group_by(type, searchtype, adjective_used, item, subid) %>%
  summarise(chose = mean(chose), n = n()) %>%
  tidyboot_mean(chose) %>%
  ungroup() %>%
  mutate(adjective_used = factor(adjective_used, labels = c("noun", "adjective noun")))
```



### Participants.

100 participants were recruited from Amazon Mechanical Turk. First, `r pilot_subjs` participants were recruited to pilot the task with size adjectives. After the pilot, a full run of the experiment was conducted: `r e1_color_subjs` participants were assigned to a condition in which the critical feature was color (stimuli contrasted on color), and `r e1_scalar_subjs` participants were assigned to a condition in which the critical feature was size.



### Stimuli.

Stimulus displays were arrays of three novel fruit objects. Fruits were chosen randomly at each trial from 25 fruit kinds. Ten of the 25 fruit drawings were adapted and redrawn from @kanwisher; we designed the remaining 15 fruit kinds. Each fruit kind has an instance in each of four colors (red, blue, green, or purple) and two sizes (big or small). There were two display types: unique target displays and contrastive displays. Unique target displays contain a target object that has a unique shape and is unique on the trial’s critical feature (color or size), and two distractor objects that match each other’s (but not the target’s) shape and critical feature. Contrastive displays contain a target, its contrastive pair (matches the target’s shape but not critical feature), and a lure (matches the target’s critical feature but not shape). The positions of the target and distractor items were randomized within a triad configuration.

```{r e1_fig, fig.env = "figure*", fig.width=6, fig.height=3, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Proportion of times that participants chose the target and lure items as a function of condition and whether an adjective was provided. Points indicate group means; error bars indicate 95\\% confidence intervals computed by non-parametric bootstrapping."}

condition_names <- c(
                    "sedivy" = "contrastive display",
                    "uniquetarget" = "unique target display",
                    "scalar" = "size",
                    "color" = "color",
                    "brightdark" = "brightness",
                    "grey" = "discrete color",
                    "greyer" = "relative color",
                    "color-prosody" = "color",
                    "scalar-prosody" = "size"
                    )
e1_mean_data %>%
  mutate(empirical_stat = if_else(searchtype == "uniquetarget" & 
                                    item == "lure", as.double(NA), empirical_stat),
         item = factor(item, levels = c("target", "lure"))) %>%
  ggplot(aes(x = adjective_used, color = item, label = item, y = empirical_stat)) +
  facet_grid(type ~ searchtype, labeller = as_labeller(condition_names)) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper),
                  position = position_dodge(.25)) + 
  scale_color_ptol() + 
  ylab("Item chosen") + 
  xlab("") + 
  geom_dl(method = list(dl.trans(x=x - .5), "first.qp", cex=.7)) +
  theme(legend.position = "none")
```


### Design and Procedure.

Participants were told they would play a game in which they would search for strange alien fruits. In the size condition, each participant saw eight trials; in the color condition, each participant saw twelve trials. Half of the trials were unique target displays and half were contrastive displays. Crossed with display type, half of trials had audio instructions that described the critical feature of the target (“Find the [blue/big] dax”), and half of trials had audio instructions with no adjective description (“Find the dax”). A name was randomly chosen at each trial from a list of twelve nonce names: dax, blicket, wug, toma, gade, sprock, koba, zorp, flib, boti, quen, and lomet. In the size condition, the size of the target (big or small) was also crossed with display type and instruction type. All experiment code is available on GitHub and will be accessible at time of unblinding.


## Results


```{r e1_models}
chance_comparisons <- e1_data %>%
  filter(searchtype == "uniquetarget", item == "target") %>% 
  group_by(adjective_used, type, subid)

glmer_chance_comparison <- chance_comparisons %>%
  filter(!adjective_used) %>%
  group_by(type) %>%
  mutate(options = 3) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(chose ~  (1|subid), offset = logit(1/options),
                                  family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

glmer_unique <- chance_comparisons %>%
  glmer(chose ~ type * adjective_used + (1|subid), family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed")
```


We first confirmed that participants understood the task by analyzing performance on trials in which there was a target unique on both shape and the relevant adjective. The below results hold for the pilot with size adjectives, but we report values from the full run of both conditions. We asked whether participants chose the target more often than expected by chance ($33\%$) by fitting a mixed effects logistic regression with an intercept term, a random effect of subject, and an offset of $logit(1/3)$ to set chance probability to the correct level. The intercept term was reliably different from zero for both color ($\beta =$ `r glmer_chance_comparison %>% filter(type == "color") %>% pull(estimate)`, $t =$ `r glmer_chance_comparison %>% filter(type == "color") %>% pull(statistic)`, $p$ `r glmer_chance_comparison %>% filter(type == "color") %>% pull(p.value) %>% printp()`) and size ($\beta =$ `r glmer_chance_comparison %>% filter(type == "scalar") %>% pull(estimate)`, $t =$ `r glmer_chance_comparison %>% filter(type == "scalar") %>% pull(statistic)`, $p$ `r glmer_chance_comparison %>% filter(type == "scalar") %>% pull(p.value) %>% printp()`). In addition, participants were more likely to select the target when an adjective was provided in the audio instruction in both conditions. We confirmed this effect statistically by fitting a mixed effects logistic regression predicting target selection from condition, adjective use, and their interaction with random effects of participants. Adjective type (color vs. size) was not statistically related to target choice ($\beta =$ `r glmer_unique %>% filter(term == "typescalar") %>% pull(estimate)`, $t =$ `r glmer_unique %>% filter(term == "typescalar") %>% pull(statistic)`, $p =$ `r glmer_unique %>% filter(term == "typescalar") %>% pull(p.value) %>% printp()`), and adjective description in the audio increased target choice ($\beta =$ `r glmer_unique %>% filter(term == "adjective_usedTRUE") %>% pull(estimate)`, $t =$ `r glmer_unique %>% filter(term == "adjective_usedTRUE") %>% pull(statistic)`, $p$ `r glmer_unique %>% filter(term == "adjective_usedTRUE") %>% pull(p.value) %>% printp()`). The two effects did not interact ($\beta =$ `r glmer_unique %>% filter(term == "typescalar:adjective_usedTRUE") %>% pull(estimate)`, $t =$ `r glmer_unique %>% filter(term == "typescalar:adjective_usedTRUE") %>% pull(statistic)`, $p =$ `r glmer_unique %>% filter(term == "typescalar:adjective_usedTRUE") %>% pull(p.value) %>% printp()`). Participants had a general tendency to choose the target in unique target trials, which was amplified if the audio instruction contained the relevant contrast adjective.

```{r e1_models_contrast}
chance_comparisons_contrast <- e1_data %>%
  filter(searchtype == "sedivy", item == "target") %>% 
  group_by(adjective_used, type, subid)

glmer_chance_comparison_contrast <- chance_comparisons_contrast %>%
  filter(adjective_used) %>%
  group_by(type) %>%
  mutate(options = 2) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(chose ~  (1|subid), offset = logit(1/options),
                                  family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

glmer_chance_comparison_contrast_noadj <- chance_comparisons_contrast %>%
  filter(!adjective_used) %>%
  group_by(type) %>%
  mutate(options = 3) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(chose ~  (1|subid), offset = logit(1/options),
                                  family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

glmer_unique_contrast <- chance_comparisons_contrast %>%
  glmer(chose ~ type * adjective_used + (1|subid), family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed")

contrast_comparison <- e1_data %>%
  filter(searchtype == "sedivy", adjective_used) %>%
  spread(item, chose) %>%
  mutate(target = as.numeric(target),
         lure = as.numeric(lure)) %>%
  group_by(type) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(cbind(target,lure) ~ 1 + (1|subid), 
      family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

contrast_comparison_pilot <- pilot_data %>%
  filter(searchtype == "sedivy", adjective_used) %>%
  spread(item, chose) %>%
  mutate(target = as.numeric(target),
         lure = as.numeric(lure)) %>%
  group_by(type) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(cbind(target,lure) ~ 1 + (1|subid), 
      family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

contrast_comparison_noadj <- e1_data %>%
  filter(searchtype == "sedivy", !adjective_used) %>%
  spread(item, chose) %>%
  mutate(target = as.numeric(target),
         lure = as.numeric(lure)) %>%
  group_by(type) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(cbind(target,lure) ~ 1 + (1|subid), 
      family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

```

Our key test was whether participants would choose the target object on contrastive trials in which description was given, reflecting use of a contrastive inference to choose a novel referent. To do this, we compare participants' rate of choosing the target to their rate of choosing the lure, which shares the relevant contrast feature with the target, when the audio described the contrast feature.  In the pilot data with only size adjectives, participants chose the target significantly more often than they chose the lure, demonstrating a contrastive inference in their referent choice ($\beta =$ `r contrast_comparison_pilot %>% filter(type == "scalar-pilot") %>% pull(estimate)`, $t =$ `r contrast_comparison_pilot %>% filter(type == "scalar-pilot") %>% pull(statistic)`, $p =$ `r contrast_comparison_pilot %>% filter(type == "scalar-pilot") %>% pull(p.value) %>% printp()`). In the full run, participants chose the target more than the lure in the size condition ($\beta =$ `r contrast_comparison %>% filter(type == "scalar") %>% pull(estimate)`, $t =$ `r contrast_comparison %>% filter(type == "scalar") %>% pull(statistic)`, $p =$ `r contrast_comparison %>% filter(type == "scalar") %>% pull(p.value) %>% printp()`), though more marginally. However, participants in the color condition did not choose the target significantly more often than they chose the lure ($\beta =$ `r contrast_comparison %>% filter(type == "color") %>% pull(estimate)`, $t =$ `r contrast_comparison %>% filter(type == "color") %>% pull(statistic)`, $p =$ `r contrast_comparison %>% filter(type == "color") %>% pull(p.value) %>% printp()`). On contrastive trials in which a descriptor was not given, participants dispreferred the target, instead choosing the lure object, which matched the target on the descriptor but had a unique shape; this was true across color ($\beta =$ `r contrast_comparison_noadj %>% filter(type == "color") %>% pull(estimate)`, $t =$ `r contrast_comparison_noadj %>% filter(type == "color") %>% pull(statistic)`, $p =$ `r contrast_comparison_noadj %>% filter(type == "color") %>% pull(p.value) %>% printp()`) and size ($\beta =$ `r contrast_comparison_noadj %>% filter(type == "scalar") %>% pull(estimate)`, $t =$ `r contrast_comparison_noadj %>% filter(type == "scalar") %>% pull(statistic)`, $p =$ `r contrast_comparison_noadj %>% filter(type == "scalar") %>% pull(p.value) %>% printp()`) conditions. Adjective use therefore increased target choice ($\beta =$ `r glmer_unique_contrast %>% filter(term == "adjective_usedTRUE") %>% pull(estimate)`, $t =$ `r glmer_unique_contrast %>% filter(term == "adjective_usedTRUE") %>% pull(statistic)`, $p$ `r glmer_unique_contrast %>% filter(term == "adjective_usedTRUE") %>% pull(p.value) %>% printp()`) across contrastive trials. Participants' choice of the target in the size condition was therefore not due to a prior preference for the target in contrastive displays, but relied on contrastive interpretation of the adjective.


# Experiment 2

```{r load_e2_data}
e2_data <- data %>% filter(type %in% c("brightdark", "grey", "greyer"))
                           
e2_brightdark_subjs <- e2_data %>%
  filter(type == "brightdark") %>%
  distinct(subid) %>%
  nrow()

e2_grey_subjs <- e2_data %>%
  filter(type == "grey") %>%
  distinct(subid) %>%
  nrow()

e2_greyer_subjs <- e2_data %>%
  filter(type == "greyer") %>%
  distinct(subid) %>%
  nrow()


e2_mean_data <- e2_data %>%
  filter(item != "unique", searchtype == "sedivy") %>%
  group_by(type, searchtype, adjective_used, item, subid) %>%
  summarise(chose = mean(chose), n = n()) %>%
  tidyboot_mean(chose) %>%
  ungroup() %>%
  mutate(adjective_used = factor(adjective_used, labels = c("noun", "adjective noun")))
```


```{r e2_fig, fig.env = "figure*", fig.width=6, fig.height=3, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Experiment 2 referent choice on contrastive display trials, by adjective type and whether the adjective was specified in the audio instruction."}

e2_mean_data %>%
  mutate(empirical_stat = if_else(searchtype == "uniquetarget" & 
                                    item == "lure", as.double(NA), empirical_stat),
         item = factor(item, levels = c("target", "lure"))) %>%
  ggplot(aes(x = adjective_used, color = item, label = item, y = empirical_stat)) +
  facet_wrap( ~ type, labeller = as_labeller(condition_names)) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper),
                  position = position_dodge(.25)) + 
  scale_color_ptol() + 
  ylab("Item chosen") + 
  xlab("") + 
  geom_dl(method = list(dl.trans(x=x - .5), "first.qp", cex=.7)) +
  theme(legend.position = "none")
```


The results of Experiment 1 demonstrate that adult listeners interpret color and size adjectives differently, attributing more contrastive weight to size adjectives and using them to choose novel referents accordingly. Why might adult listeners do this? As alluded to earlier, participants’ responses may reflect a symmetry between adjective production and comprehension. Since color adjectives are used more frequently and redundantly than size adjectives, listeners may attenuate the contrastive weight of color description. A second possibility, not mutually exclusive with the first, is that size is inherently more contrastive than color because size is scalar and relative whereas color is more discrete. Listeners may interpret size as more contrastive because it occurs on a continuum or because it requires comparison to other category exemplars.
	In our second experiment, we aim to examine whether manipulating the descriptor---making it more or less scalar---of the same stimulus will change participants’ contrastive inferences about color. To do so, we present stimuli with varying levels of saturation. These stimuli can be contrasted on either discrete color (blue, grey), relative color (bluer, greyer), or relative brightness (bright, dark) adjectives. By maintaining a constant set of stimuli, we can rule out explanations of the contrastive differences between adjective types that are stimulus-specific---such as some contrasts being more visually salient---to which our first experiment is susceptible.

```{r brightdarktrial, fig.env = "figure", fig.pos = "H", fig.align='center', set.cap.width=T, num.cols.cap=1, fig.cap = "Example of a contrastive trial in which the critical feature is saturation. Here, the participant would hear the instruction ``Find the [red/redder/bright] dax.'' The target is the top object. The lure is on the bottom left."}
img <- png::readPNG("figs/contrastbrightdark.png")
grid::grid.raster(img)
```
	
## Methods


### Participants.
One hundred and twenty participants were recruited from Amazon Mechanical Turk. Forty participants were assigned to a condition in which the critical contrast was discrete color (blue, grey), 40 participants were assigned to a condition in which the critical feature was relative color (bluer, greyer), and 40 participants were assigned to a condition in which the critical feature was relative brightness (bright, dark).



### Stimuli & Procedure.
Stimulus displays were arrays of three novel fruit objects, similar to those used in Experiment 1. Each fruit kind had an instance in each of four colors (red, blue, green, or purple) in two saturation levels (saturated or unsaturated). As in Experiment 1, there were two display types: unique object displays and contrastive displays. All fruit objects on any given display were the same hue. In a unique object display, the target differs from the two distractors in shape and in saturation. In a contrastive display, the target matches one distractor in shape but not in saturation, and the other distractor (the lure) in saturation but not in shape. Instructions and trial structure were identical to Experiment 1. Audio instructions diverged, this time reflecting the critical contrasts of each condition: discrete color (red, blue, green, or purple; or grey), relative color (redder, bluer, greener, or purpler; or greyer), and relative brightness (bright or dark).



```{r e2_models}
chance_comparisons_unique_2 <- e2_data %>%
  filter(searchtype == "uniquetarget", item == "target") %>% 
  group_by(adjective_used, type, subid)

glmer_chance_comparison_unique_2 <- chance_comparisons_unique_2 %>%
  filter(!adjective_used) %>%
  group_by(type) %>%
  mutate(options = 3) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(chose ~  (1|subid), offset = logit(1/options),
                                  family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

chance_comparisons_contrast_2 <- e2_data %>%
  filter(searchtype == "sedivy", item == "target") %>% 
  group_by(adjective_used, type, subid)

glmer_chance_comparison_contrast_2 <- chance_comparisons_contrast_2 %>%
  filter(adjective_used) %>%
  group_by(type) %>%
  mutate(options = 2) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(chose ~  (1|subid), offset = logit(1/options),
                                  family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

glmer_unique_2 <- chance_comparisons_unique_2 %>%
  glmer(chose ~ type * adjective_used + (1|subid), family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed")

glmer_contrast_2 <- chance_comparisons_contrast_2 %>%
  glmer(chose ~ type * adjective_used + (1|subid), family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed")

contrast_comparison2 <- e2_data %>%
  filter(searchtype == "sedivy", adjective_used) %>%
  spread(item, chose) %>%
  mutate(target = as.numeric(target),
         lure = as.numeric(lure)) %>%
  group_by(type) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(cbind(target,lure) ~ 1 + (1|subid), 
      family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

contrast_comparison2_noadj <- e2_data %>%
  filter(searchtype == "sedivy", !adjective_used) %>%
  spread(item, chose) %>%
  mutate(target = as.numeric(target),
         lure = as.numeric(lure)) %>%
  group_by(type) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(cbind(target,lure) ~ 1 + (1|subid), 
      family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")
```
## Results

We first analyzed performance on trials in which there was a target unique on both shape and the relevant contrast adjective, asking whether participants chose the target more often than expected by chance ($33\%$) by fitting a mixed effects logistic regression with an intercept term, and a random effect of subject, and an offset of $logit(1/3)$ to set chance probability to the correct level. The intercept term was reliably different from zero for color (e.g., blue, grey) ($\beta =$ `r glmer_chance_comparison_unique_2 %>% filter(type == "grey") %>% pull(estimate)`, $t =$ `r glmer_chance_comparison_unique_2 %>% filter(type == "grey") %>% pull(statistic)`, $p =$ `r glmer_chance_comparison_unique_2 %>% filter(type == "grey") %>% pull(p.value) %>% printp()`), relative color (e.g., bluer, greyer) ($\beta =$ `r glmer_chance_comparison_unique_2 %>% filter(type == "greyer") %>% pull(estimate)`, $t =$ `r glmer_chance_comparison_unique_2 %>% filter(type == "greyer") %>% pull(statistic)`, $p$ `r glmer_chance_comparison_unique_2 %>% filter(type == "greyer") %>% pull(p.value) %>% printp()`), and brightness (e.g., bright, dark) ($\beta =$ `r glmer_chance_comparison_unique_2 %>% filter(type == "brightdark") %>% pull(estimate)`, $t =$ `r glmer_chance_comparison_unique_2 %>% filter(type == "brightdark") %>% pull(statistic)`, $p$ `r glmer_chance_comparison_unique_2 %>% filter(type == "brightdark") %>% pull(p.value) %>% printp()`). Adjective use did not significantly increase target choice ($\beta =$ `r glmer_unique_2 %>% filter(term == "adjective_usedTRUE") %>% pull(estimate)`, $t =$ `r glmer_unique_2 %>% filter(term == "adjective_usedTRUE") %>% pull(statistic)`, $p =$ `r glmer_unique_2 %>% filter(term == "adjective_usedTRUE") %>% pull(p.value) %>% printp()`). Participants had a general tendency to choose the target in unique target trials, but there was no significant main effect of adjective use on these trials. 


Our key test was whether participants would choose the target object on contrastive trials when description was given, reflecting use of a contrastive inference to choose a novel referent. Across all adjective types, participants did not choose the target significantly more than they chose the lure, in fact showing a numerical preference for the lure in each condition and a significant preference for the lure in the discrete color (e.g., blue, grey) condition (for discrete color: $\beta =$ `r contrast_comparison2 %>% filter(type == "grey") %>% pull(estimate)`, $t =$ `r contrast_comparison2 %>% filter(type == "grey") %>% pull(statistic)`, $p =$ `r contrast_comparison2 %>% filter(type == "grey") %>% pull(p.value) %>% printp()`; for relative color: $\beta =$ `r contrast_comparison2 %>% filter(type == "greyer") %>% pull(estimate)`, $t =$ `r contrast_comparison2 %>% filter(type == "greyer") %>% pull(statistic)`, $p =$ `r contrast_comparison2 %>% filter(type == "greyer") %>% pull(p.value) %>% printp()`; for brightness: $\beta =$ `r contrast_comparison2 %>% filter(type == "brightdark") %>% pull(estimate)`, $t =$ `r contrast_comparison2 %>% filter(type == "brightdark") %>% pull(statistic)`, $p =$ `r contrast_comparison2 %>% filter(type == "brightdark") %>% pull(p.value) %>% printp()`). Preference for the lure was also demonstrated when the adjective was not specified (for discrete color: $\beta =$ `r contrast_comparison2_noadj %>% filter(type == "grey") %>% pull(estimate)`, $t =$ `r contrast_comparison2_noadj %>% filter(type == "grey") %>% pull(statistic)`, $p =$ `r contrast_comparison2_noadj %>% filter(type == "grey") %>% pull(p.value) %>% printp()`; for relative color: $\beta =$ `r contrast_comparison2_noadj %>% filter(type == "greyer") %>% pull(estimate)`, $t =$ `r contrast_comparison2_noadj %>% filter(type == "greyer") %>% pull(statistic)`, $p =$ `r contrast_comparison2_noadj %>% filter(type == "greyer") %>% pull(p.value) %>% printp()`; for brightness: $\beta =$ `r contrast_comparison2_noadj %>% filter(type == "brightdark") %>% pull(estimate)`, $t =$ `r contrast_comparison2_noadj %>% filter(type == "brightdark") %>% pull(statistic)`, $p =$ `r contrast_comparison2_noadj %>% filter(type == "brightdark") %>% pull(p.value) %>% printp()`). Across these conditions, participants did not consistently demonstrate a contrastive interpretation in their referent choices, and in fact tended to avoid contrastive choices. This may in part be due to a strong prior preference for the lure object, but nonetheless means that contrastive selection did not emerge.

# Experiment 3
```{r load_e3_data}
e3_data <- data %>% filter(type %in% c("scalar-prosody", "color-prosody"))
                           
e3_scalar_subjs <- e3_data %>%
  filter(type == "scalar-prosody") %>%
  distinct(subid) %>%
  nrow()

e3_color_subjs <- e3_data %>%
  filter(type == "color-prosody") %>%
  distinct(subid) %>%
  nrow()

e3_mean_data <- e3_data %>%
  filter(item != "unique", searchtype == "sedivy") %>%
  group_by(type, searchtype, adjective_used, item, subid) %>%
  summarise(chose = mean(chose), n = n()) %>%
  tidyboot_mean(chose) %>%
  ungroup() %>%
  mutate(adjective_used = factor(adjective_used, labels = c("noun", "adjective noun")))
```


```{r e3_fig, fig.env = "figure*", fig.width=6, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Experiment 3 referent choice on contrastive display trials, by adjective type (color or size) and whether the adjective was specified (with prosodic stress) in the audio instruction."}

e3_mean_data %>%
  mutate(empirical_stat = if_else(searchtype == "uniquetarget" & 
                                    item == "lure", as.double(NA), empirical_stat),
         item = factor(item, levels = c("target", "lure"))) %>%
  ggplot(aes(x = adjective_used, color = item, label = item, y = empirical_stat)) +
  facet_wrap( ~ type, labeller = as_labeller(condition_names)) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper),
                  position = position_dodge(.25)) + 
  scale_color_ptol() + 
  ylab("Item chosen") + 
  xlab("") + 
  geom_dl(method = list(dl.trans(x=x - .5), "first.qp", cex=.7)) +
  theme(legend.position = "none")
```
The results of Experiment 2 suggest that color is not easily interpreted contrastively, even when descriptors suggest a scalar interpretation.  Given that color has contrastive weight in implicit measures in specific contexts [@sedivy_achieving_1999; @sedivy_pragmatic_2003-2], and fails to do so in our explicit measure, perhaps participants needed a more explicit pragmatic cue to contrastiveness. To test whether an explicit pragmatic cue would induce contrastive inferences, in Experiment 3 we manipulate prosody.

The placement of prosodic stress on a word tends to evoke its set of alternatives, inducing a contrastive interpretation. In early work on incremental semantic processing [@eberhard_eye_1995], participants saw displays containing, for example, a large blue square, a small blue square, a large yellow circle, and a small red triangle. Hearing an instruction with contrastive stress on the size adjective—“Find the *large* blue square”—facilitated their fixation on the target compared to instructions without contrastive stress. In Experiment 3, we test whether adding contrastive stress on the adjective in our instructions facilitates an explicit contrastive referent choice.


## Methods
### Participants.
Eighty participants were recruited from Amazon Mechanical Turk. Forty participants were assigned to a condition identical to the color contrast condition in Experiment 1, with the modification that audio stimuli included stress on the color adjective. Forty participants were assigned to a condition identical to the size contrast condition in Experiment 1, with the modification that audio stimuli included stress on the size adjective. 

### Stimuli and Procedure.
Stimulus displays were identical to those in Experiment 1. Audio stimuli were recorded such that utterances containing an adjective had contrastive stress on the adjective (e.g., “Find the *small* blicket”). Instructions and trial structure were identical to Experiment 1.

```{r e3_models}
chance_comparisons_unique_3 <- e3_data %>%
  filter(searchtype == "uniquetarget", item == "target") %>% 
  group_by(adjective_used, type, subid)

glmer_chance_comparison_unique_3 <- chance_comparisons_unique_3 %>%
  filter(!adjective_used) %>%
  group_by(type) %>%
  mutate(options = 3) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(chose ~  (1|subid), offset = logit(1/options),
                                  family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

chance_comparisons_contrast_3 <- e3_data %>%
  filter(searchtype == "sedivy", item == "target") %>% 
  group_by(adjective_used, type, subid)

glmer_chance_comparison_contrast_3 <- chance_comparisons_contrast_3 %>%
  filter(adjective_used) %>%
  group_by(type) %>%
  mutate(options = 2) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(chose ~  (1|subid), offset = logit(1/options),
                                  family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")

glmer_unique_3 <- chance_comparisons_unique_3 %>%
  glmer(chose ~ type * adjective_used + (1|subid), family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed")

contrast_comparison3 <- e3_data %>%
  filter(searchtype == "sedivy", adjective_used) %>%
  spread(item, chose) %>%
  mutate(target = as.numeric(target),
         lure = as.numeric(lure)) %>%
  group_by(type) %>%
  nest() %>%
  mutate(model = map(data, ~glmer(cbind(target,lure) ~ 1 + (1|subid), 
      family = "binomial", data = .))) %>%
  mutate(model = map(model, tidy)) %>%
  select(-data) %>%
  unnest() %>%
  filter(effect == "fixed")
```

## Results

We first asked whether participants chose the target more often than expected by chance ($33\%$) on unique target trials by fitting a mixed effects logistic regression with an intercept term, and a random effect of subject, and an offset of $logit(1/3)$ to set chance probability to the correct level. The intercept term was reliably different from zero for the color ($\beta =$ `r glmer_chance_comparison_unique_3 %>% filter(type == "color-prosody") %>% pull(estimate)`, $t =$ `r glmer_chance_comparison_unique_3 %>% filter(type == "color-prosody") %>% pull(statistic)`, $p$ `r glmer_chance_comparison_unique_3 %>% filter(type == "color-prosody") %>% pull(p.value) %>% printp()`) and size ($\beta =$ `r glmer_chance_comparison_unique_3 %>% filter(type == "scalar-prosody") %>% pull(estimate)`, $t =$ `r glmer_chance_comparison_unique_3 %>% filter(type == "scalar-prosody") %>% pull(statistic)`, $p$ `r glmer_chance_comparison_unique_3 %>% filter(type == "scalar-prosody") %>% pull(p.value) %>% printp()`) conditions. Adjective type (color vs. size) was not statistically related to target choice ($\beta =$ `r glmer_unique_3 %>% filter(term == "typescalar-prosody") %>% pull(estimate)`, $t =$ `r glmer_unique_3 %>% filter(term == "typescalar-prosody") %>% pull(statistic)`, $p =$ `r glmer_unique_3 %>% filter(term == "typescalar-prosody") %>% pull(p.value) %>% printp()`), and adjective use did not significantly increase target choice ($\beta =$ `r glmer_unique_3 %>% filter(term == "adjective_usedTRUE") %>% pull(estimate)`, $t =$ `r glmer_unique_3 %>% filter(term == "adjective_usedTRUE") %>% pull(statistic)`, $p =$ `r glmer_unique_3 %>% filter(term == "adjective_usedTRUE") %>% pull(p.value) %>% printp()`).
 

Our key test was whether participants would choose the target object on contrastive trials when description was given with contrastive stress, reflecting use of the descriptor and/or prosodic stress to choose the referent. In the size condition, participants chose the target more often than they chose the lure, though this difference did not reach significance ($\beta =$ `r contrast_comparison3 %>% filter(type == "scalar-prosody") %>% pull(estimate)`, $t =$ `r contrast_comparison3 %>% filter(type == "scalar-prosody") %>% pull(statistic)`, $p =$ `r contrast_comparison3 %>% filter(type == "scalar-prosody") %>% pull(p.value) %>% printp()`). In the color condition, participants chose the lure numerically more than they chose the target, and the difference was not significant ($\beta =$ `r contrast_comparison3 %>% filter(type == "color-prosody") %>% pull(estimate)`, $t =$ `r contrast_comparison3 %>% filter(type == "color-prosody") %>% pull(statistic)`, $p =$ `r contrast_comparison3 %>% filter(type == "color-prosody") %>% pull(p.value) %>% printp()`). In this task, contrastive stress did not encourage a contrastive referent choice. Though the data patterned similarly to that of Experiment 1, with participants in the size condition choosing the target more often than they chose the lure, this difference did not reach significance.

# Discussion

In this series of experiments, we asked whether listeners could use pragmatic contrast to resolve referential ambiguity. Participants were able to use size adjectives contrastively to establish a novel word–referent mapping. Their contrastive inference goes beyond the implicit attention allocation shown in prior eye-tracking paradigms [@sedivy_achieving_1999;@huangsnedeker2008], determining explicit referent choice. This finding bolsters contrastive inference as a viable tool for referential disambiguation.

Participants failed, however, to use color adjectives contrastively in choosing referents. What makes size different from color? One possibility is that the scalar nature of size supports a contrastive interpretation. We tested whether using relative color adjectives (e.g., bluer, greyer) or adjectives describing value (bright, dark) on saturated and desaturated stimuli would encourage the contrastive inference. We also tested whether adding a prosodic cue to contrast (e.g., “Find the *blue* dax”) would encourage contrastive inference. Participants persisted in interpreting color non-contrastively, never consistently choosing the intended target over the lure. Though we do not claim that contrastive color inferences cannot be used to explicitly choose referents, it seems that a contrastive interpretation is difficult to elicit using color, while it emerges under similar conditions using size.

Another possibility is that color adjectives are often used redundantly, and therefore receive less contrastive weight than adjectives consistently used to differentiate between referents. Sedivy (2003) puts forth such an account, finding that color adjectives tend not to be interpreted contrastively in eye-tracking measures except in contexts that make their use unlikely. In comparison, adjectives describing material (e.g., plastic) and size are interpreted contrastively, which corresponds to less redundant use of material and size adjectives in production [@sedivy_pragmatic_2003-2; see Chapter 10 of @gibson_processing_2011]. This account explains well why color is not interpreted contrastively here, but fails to explain why presumably rare adjectives (bluer, bright) do not receive contrastive treatment in our task. Further work is necessary to determine whether contrastive inferences hew to production norms, and whether implicit indications of contrast usually extend to explicit referent choice.

Though the participants in our experiments were adults, the ability to disambiguate novel referents using contrast most obviously serves budding language learners: children. Contrastive use of adjectives is a pragmatic regularity in language that children could potentially exploit to establish word--referent mappings. Tasks using a mixture of novel adjectives and words suggest that children as young as 3 can make contrastive inferences about adjectives [@gelman_implicit_1985; @diesendruck_childrens_2006; @huangsnedeker2008]. We plan to research further the development of these contrastive skills, as well as their potential as tools for extracting information from language and context.

#Conclusion
We establish here that adult listeners are able to use contrastive inference to map novel words to novel referents. This ability is limited, however: it emerges with size but not color description. This result accords with findings that size adjectives more reliably evoke contrast in eye-tracking measures [@sedivy_pragmatic_2003-2]. Our manipulations in Experiment 2 to make color more relative, which did not result in contrastive inference, suggest that an explanation of size's effect based only on its scalar nature is insufficient. An account that relates production norms to listener interpretation may better explain our findings. Further research to determine the relationship between contrastive production and contrastive inference across adjective types, as well as the relationship between implicit measures of contrastive inference and explicit referent choice, is ongoing.


# References
